{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "import numpy as np\n",
    "\n",
    "## MAKE A CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2142 entries, 0 to 2141\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Online Post ID          2142 non-null   int64  \n",
      " 1   Twitter ID              1673 non-null   float64\n",
      " 2   Related Online Post ID  333 non-null    float64\n",
      " 3   Source ID               2142 non-null   object \n",
      " 4   Online Post Text        469 non-null    object \n",
      " 5   Subjectivity            2142 non-null   int64  \n",
      " 6   Sentiment Polarity      2142 non-null   object \n",
      " 7   Emotion                 2142 non-null   object \n",
      " 8   Sarcasm                 2142 non-null   int64  \n",
      " 9   Irony                   2142 non-null   int64  \n",
      " 10  Negation                2142 non-null   int64  \n",
      " 11  Off-topic               2142 non-null   int64  \n",
      " 12  Language                2142 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 217.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2316 entries, 0 to 2315\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Online Post ID          2316 non-null   int64  \n",
      " 1   Twitter ID              1677 non-null   float64\n",
      " 2   Related Online Post ID  448 non-null    float64\n",
      " 3   Source ID               2316 non-null   object \n",
      " 4   Online Post Text        639 non-null    object \n",
      " 5   Subjectivity            2316 non-null   int64  \n",
      " 6   Sentiment Polarity      2316 non-null   object \n",
      " 7   Emotion                 2316 non-null   object \n",
      " 8   Sarcasm                 2316 non-null   int64  \n",
      " 9   Irony                   2316 non-null   int64  \n",
      " 10  Negation                2316 non-null   int64  \n",
      " 11  Off-topic               2316 non-null   int64  \n",
      " 12  Language                2316 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 235.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1929 entries, 0 to 1928\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Online Post ID          1929 non-null   int64  \n",
      " 1   Twitter ID              1314 non-null   float64\n",
      " 2   Related Online Post ID  396 non-null    float64\n",
      " 3   Source ID               1929 non-null   object \n",
      " 4   Online Post Text        615 non-null    object \n",
      " 5   Subjectivity            1929 non-null   int64  \n",
      " 6   Sentiment Polarity      1929 non-null   object \n",
      " 7   Emotion                 1929 non-null   object \n",
      " 8   Sarcasm                 1929 non-null   int64  \n",
      " 9   Irony                   1929 non-null   int64  \n",
      " 10  Negation                1929 non-null   int64  \n",
      " 11  Off-topic               1929 non-null   int64  \n",
      " 12  Language                1929 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 196.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "malta_loc_18 = '../data/Malta-Budget-2018-dataset-v1.csv'\n",
    "malta_loc_19 = '../data/Malta-Budget-2019-dataset-v1.csv'\n",
    "malta_loc_20 = '../data/Malta-Budget-2020-dataset-v1.csv'\n",
    "\n",
    "malta_data_18 = pd.read_csv(malta_loc_18)\n",
    "malta_data_19 = pd.read_csv(malta_loc_19)\n",
    "malta_data_20 = pd.read_csv(malta_loc_20)\n",
    "\n",
    "print(malta_data_18.info())\n",
    "print(malta_data_19.info())\n",
    "print(malta_data_20.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data files into single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6387 entries, 0 to 6386\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Online Post ID          6387 non-null   int64  \n",
      " 1   Twitter ID              4664 non-null   float64\n",
      " 2   Related Online Post ID  1177 non-null   float64\n",
      " 3   Source ID               6387 non-null   object \n",
      " 4   Online Post Text        1723 non-null   object \n",
      " 5   Subjectivity            6387 non-null   int64  \n",
      " 6   Sentiment Polarity      6387 non-null   object \n",
      " 7   Emotion                 6387 non-null   object \n",
      " 8   Sarcasm                 6387 non-null   int64  \n",
      " 9   Irony                   6387 non-null   int64  \n",
      " 10  Negation                6387 non-null   int64  \n",
      " 11  Off-topic               6387 non-null   int64  \n",
      " 12  Language                6387 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 648.8+ KB\n"
     ]
    }
   ],
   "source": [
    "malta_data_19 = malta_data_19.rename(columns={'Off-topic ':'Off-topic'})\n",
    "combined_data = pd.concat([malta_data_18, malta_data_19, malta_data_20], ignore_index=True)\n",
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up of data columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Irony</th>\n",
       "      <th>Negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180001</td>\n",
       "      <td>Great BUDGET . Even cigarettes were not touche...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180002</td>\n",
       "      <td>I haven't exactly scanned the budget throughou...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180003</td>\n",
       "      <td>There’s already smoking cessation programs for...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180004</td>\n",
       "      <td>So should alcohol and fuel for private vehicle...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180005</td>\n",
       "      <td>Practical? You should say that in a third worl...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               Text  Subjectivity  \\\n",
       "0  20180001  Great BUDGET . Even cigarettes were not touche...             1   \n",
       "1  20180002  I haven't exactly scanned the budget throughou...             1   \n",
       "2  20180003  There’s already smoking cessation programs for...             1   \n",
       "3  20180004  So should alcohol and fuel for private vehicle...             1   \n",
       "4  20180005  Practical? You should say that in a third worl...             1   \n",
       "\n",
       "  Sentiment Polarity       Emotion  Sarcasm  Irony  Negation  \n",
       "0           positive         trust        0      0         1  \n",
       "1           negative       disgust        0      0         1  \n",
       "2            neutral  anticipation        0      0         0  \n",
       "3           negative       sadness        0      0         0  \n",
       "4           negative         anger        0      0         1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = combined_data.dropna(subset=['Online Post Text'])\n",
    "clean_data = clean_data.drop(['Twitter ID', 'Related Online Post ID', 'Source ID','Off-topic'], axis=1)\n",
    "clean_data = clean_data[clean_data['Language'] == 0] # get all data that is in english \n",
    "clean_data = clean_data.drop(['Language'], axis=1)\n",
    "clean_data = clean_data.rename(columns={'Online Post ID':'ID','Online Post Text':'Text'})\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1114 entries, 0 to 5072\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   ID                  1114 non-null   int64 \n",
      " 1   Text                1114 non-null   object\n",
      " 2   Subjectivity        1114 non-null   int64 \n",
      " 3   Sentiment Polarity  1114 non-null   object\n",
      " 4   Emotion             1114 non-null   object\n",
      " 5   Sarcasm             1114 non-null   int64 \n",
      " 6   Irony               1114 non-null   int64 \n",
      " 7   Negation            1114 non-null   int64 \n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disgust         253\n",
       "anger           225\n",
       "anticipation    199\n",
       "sadness         138\n",
       "joy              95\n",
       "surprise         92\n",
       "trust            67\n",
       "fear             45\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"Emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "value_counts = clean_data['Emotion'].value_counts()\n",
    "\n",
    "# Plotting the frequency of string values in the 'Category' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=value_counts.index, y=value_counts.values, palette='viridis')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Emotional Categories In English Comments about The Maltese Budget 2018-2020')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Irony</th>\n",
       "      <th>Negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180001</td>\n",
       "      <td>great budget even cigarette touched great work...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180002</td>\n",
       "      <td>exactly scanned budget throughout earth make i...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180003</td>\n",
       "      <td>already smoking cessation program people want ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180004</td>\n",
       "      <td>alcohol fuel private vehicle raising tax cigar...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180005</td>\n",
       "      <td>practical say third world country supposed eur...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               Text  Subjectivity  \\\n",
       "0  20180001  great budget even cigarette touched great work...             1   \n",
       "1  20180002  exactly scanned budget throughout earth make i...             1   \n",
       "2  20180003  already smoking cessation program people want ...             1   \n",
       "3  20180004  alcohol fuel private vehicle raising tax cigar...             1   \n",
       "4  20180005  practical say third world country supposed eur...             1   \n",
       "\n",
       "  Sentiment Polarity       Emotion  Sarcasm  Irony  Negation  \n",
       "0           positive         trust        0      0         1  \n",
       "1           negative       disgust        0      0         1  \n",
       "2            neutral  anticipation        0      0         0  \n",
       "3           negative       sadness        0      0         0  \n",
       "4           negative         anger        0      0         1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    pattern = re.compile(r'[^a-zA-Z\\s]')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "# Remove URLs and HTML tags\n",
    "clean_data['Text'] = clean_data['Text'].str.replace(r'http\\S+|www\\S+|https\\S+', '', regex=True)\n",
    "clean_data['Text'] = clean_data['Text'].str.replace(r'<.*?>', '', regex=True)\n",
    "\n",
    "# Expand contractions\n",
    "clean_data['Text'] = clean_data['Text'].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "# Convert to lowercase\n",
    "clean_data['Text'] = clean_data['Text'].str.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "clean_data['Text'] = clean_data['Text'].str.replace(f\"[{string.punctuation}]\", \" \", regex=True)\n",
    "\n",
    "# Remove numbers\n",
    "clean_data['Text'] = clean_data['Text'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "# Remove special characters\n",
    "clean_data['Text'] = clean_data['Text'].apply(remove_special_characters)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "clean_data['Text'] = clean_data['Text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "\n",
    "# Remove extra whitespace\n",
    "clean_data['Text'] = clean_data['Text'].str.strip()\n",
    "clean_data['Text'] = clean_data['Text'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "clean_data['Text'] = clean_data['Text'].apply(lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split()))\n",
    "\n",
    "# Tokenize\n",
    "# clean_data['tokens'] = clean_data['Text'].apply(word_tokenize)\n",
    " \n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180001</td>\n",
       "      <td>great budget even cigarette touched great work...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180002</td>\n",
       "      <td>exactly scanned budget throughout earth make i...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180003</td>\n",
       "      <td>already smoking cessation program people want ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180004</td>\n",
       "      <td>alcohol fuel private vehicle raising tax cigar...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180005</td>\n",
       "      <td>practical say third world country supposed eur...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               Text       Emotion\n",
       "0  20180001  great budget even cigarette touched great work...         trust\n",
       "1  20180002  exactly scanned budget throughout earth make i...       disgust\n",
       "2  20180003  already smoking cessation program people want ...  anticipation\n",
       "3  20180004  alcohol fuel private vehicle raising tax cigar...       sadness\n",
       "4  20180005  practical say third world country supposed eur...         anger"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripped_data = clean_data.drop(columns=['Subjectivity','Sentiment Polarity', 'Sarcasm','Irony','Negation'])\n",
    "stripped_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28699551569506726\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.19      0.31      0.24        45\n",
      "anticipation       0.43      0.45      0.44        40\n",
      "     disgust       0.32      0.51      0.39        51\n",
      "        fear       0.50      0.11      0.18         9\n",
      "         joy       0.00      0.00      0.00        19\n",
      "     sadness       0.29      0.18      0.22        28\n",
      "    surprise       0.00      0.00      0.00        18\n",
      "       trust       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.29       223\n",
      "   macro avg       0.22      0.20      0.18       223\n",
      "weighted avg       0.25      0.29      0.25       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "train_df, test_df = train_test_split(stripped_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['Text'])\n",
    "X_test = vectorizer.transform(test_df['Text'])\n",
    "\n",
    "# Labels\n",
    "y_train = train_df['Emotion']\n",
    "y_test = test_df['Emotion']\n",
    "\n",
    "# Training Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.1535 - loss: 2.0346 - val_accuracy: 0.2332 - val_loss: 1.9028\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2710 - loss: 1.9193 - val_accuracy: 0.2242 - val_loss: 1.8925\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3219 - loss: 1.7809 - val_accuracy: 0.1973 - val_loss: 1.8765\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5454 - loss: 1.4846 - val_accuracy: 0.2063 - val_loss: 1.8857\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6973 - loss: 0.9855 - val_accuracy: 0.2422 - val_loss: 1.9234\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8772 - loss: 0.5426 - val_accuracy: 0.2780 - val_loss: 2.0262\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9616 - loss: 0.2812 - val_accuracy: 0.2735 - val_loss: 2.1436\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9784 - loss: 0.1532 - val_accuracy: 0.3094 - val_loss: 2.2752\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9916 - loss: 0.0740 - val_accuracy: 0.2735 - val_loss: 2.4009\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9881 - loss: 0.0717 - val_accuracy: 0.3049 - val_loss: 2.4672\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9938 - loss: 0.0424 - val_accuracy: 0.2915 - val_loss: 2.5601\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9933 - loss: 0.0354 - val_accuracy: 0.2735 - val_loss: 2.6490\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9971 - loss: 0.0264 - val_accuracy: 0.2825 - val_loss: 2.7358\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9946 - loss: 0.0270 - val_accuracy: 0.3004 - val_loss: 2.8015\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9927 - loss: 0.0324 - val_accuracy: 0.2780 - val_loss: 2.8389\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9955 - loss: 0.0219 - val_accuracy: 0.2960 - val_loss: 2.8497\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9985 - loss: 0.0121 - val_accuracy: 0.2780 - val_loss: 2.9624\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9929 - loss: 0.0161 - val_accuracy: 0.2646 - val_loss: 2.9625\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9969 - loss: 0.0146 - val_accuracy: 0.2915 - val_loss: 3.0055\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9946 - loss: 0.0156 - val_accuracy: 0.2735 - val_loss: 3.0960\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2721 - loss: 3.1712 \n",
      "Test Loss: 3.2420194149017334\n",
      "Test Accuracy: 0.2735426127910614\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer, one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, MaxPooling2D, Conv2D\n",
    "\n",
    "# Tokenization and Padding\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(stripped_data['Text'])\n",
    "sequences = tokenizer.texts_to_sequences(stripped_data['Text'])\n",
    "x_data = pad_sequences(sequences, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with One Hot Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.1682 - loss: 2.0427 - val_accuracy: 0.2018 - val_loss: 1.9249\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2489 - loss: 1.9065 - val_accuracy: 0.2242 - val_loss: 1.9144\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.3241 - loss: 1.8271 - val_accuracy: 0.2556 - val_loss: 1.8917\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5012 - loss: 1.6129 - val_accuracy: 0.2691 - val_loss: 1.8655\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6261 - loss: 1.2103 - val_accuracy: 0.2646 - val_loss: 1.9243\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8056 - loss: 0.7505 - val_accuracy: 0.2601 - val_loss: 2.0873\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9119 - loss: 0.4169 - val_accuracy: 0.2152 - val_loss: 2.2439\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9775 - loss: 0.2106 - val_accuracy: 0.2242 - val_loss: 2.4408\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9747 - loss: 0.1207 - val_accuracy: 0.2242 - val_loss: 2.6192\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9937 - loss: 0.0690 - val_accuracy: 0.2242 - val_loss: 2.7842\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9792 - loss: 0.0701 - val_accuracy: 0.2287 - val_loss: 2.8453\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9946 - loss: 0.0463 - val_accuracy: 0.2422 - val_loss: 2.9358\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9934 - loss: 0.0371 - val_accuracy: 0.2466 - val_loss: 3.1983\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9948 - loss: 0.0271 - val_accuracy: 0.2377 - val_loss: 3.2837\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9926 - loss: 0.0232 - val_accuracy: 0.2466 - val_loss: 3.2703\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9907 - loss: 0.0261 - val_accuracy: 0.2287 - val_loss: 3.4118\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9990 - loss: 0.0170 - val_accuracy: 0.2422 - val_loss: 3.5071\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9982 - loss: 0.0136 - val_accuracy: 0.2466 - val_loss: 3.4799\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9976 - loss: 0.0147 - val_accuracy: 0.2422 - val_loss: 3.5754\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9933 - loss: 0.0168 - val_accuracy: 0.2466 - val_loss: 3.6507\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2391 - loss: 3.8175 \n",
      "Test Loss: 3.805290937423706\n",
      "Test Accuracy: 0.2466367781162262\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">452,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m452,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,444</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m462,444\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,444</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m462,444\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2277 - loss: 2.0449 - val_accuracy: 0.2287 - val_loss: 1.9396\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2307 - loss: 1.9321 - val_accuracy: 0.2287 - val_loss: 1.9174\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2444 - loss: 1.8897 - val_accuracy: 0.2287 - val_loss: 1.9010\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2476 - loss: 1.7523 - val_accuracy: 0.2197 - val_loss: 1.8999\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2955 - loss: 1.6603 - val_accuracy: 0.2332 - val_loss: 1.9129\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3957 - loss: 1.4721 - val_accuracy: 0.2556 - val_loss: 1.9461\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5492 - loss: 1.2698 - val_accuracy: 0.1928 - val_loss: 1.9910\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6979 - loss: 0.9722 - val_accuracy: 0.2332 - val_loss: 2.0783\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7272 - loss: 0.8168 - val_accuracy: 0.2242 - val_loss: 2.1624\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7852 - loss: 0.6505 - val_accuracy: 0.1928 - val_loss: 2.3054\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7899 - loss: 0.5930 - val_accuracy: 0.1794 - val_loss: 2.4033\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8133 - loss: 0.5272 - val_accuracy: 0.1614 - val_loss: 2.5818\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8143 - loss: 0.4798 - val_accuracy: 0.1839 - val_loss: 2.5580\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8652 - loss: 0.4802 - val_accuracy: 0.1794 - val_loss: 2.6983\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8593 - loss: 0.4208 - val_accuracy: 0.1435 - val_loss: 2.8591\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8668 - loss: 0.4377 - val_accuracy: 0.1749 - val_loss: 2.8896\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8923 - loss: 0.3489 - val_accuracy: 0.1749 - val_loss: 3.0446\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8924 - loss: 0.3133 - val_accuracy: 0.1614 - val_loss: 3.1508\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9080 - loss: 0.2933 - val_accuracy: 0.1839 - val_loss: 3.4852\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8996 - loss: 0.2981 - val_accuracy: 0.1390 - val_loss: 3.7654\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1331 - loss: 3.8352 \n",
      "Test Loss: 3.7715821266174316\n",
      "Test Accuracy: 0.13901345431804657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "\n",
    "# Convert text data to numerical vectors\n",
    "count_vectorizer = CountVectorizer(max_features=max_features)\n",
    "x_data = count_vectorizer.fit_transform(stripped_data['Text']).toarray()\n",
    "\n",
    "# Label encoding for emotion\n",
    "label_encoder = LabelEncoder()\n",
    "y_data = label_encoder.fit_transform(stripped_data['Emotion'])\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=y_data, random_state=42)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Dense(embedding_dim, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Reshape((embedding_dim, 1)))  # Reshape to match Conv1D input shape\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Oridinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">452,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m452,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,444</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m462,444\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,444</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m462,444\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2135 - loss: 2.0616 - val_accuracy: 0.2287 - val_loss: 1.9689\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2058 - loss: 1.9504 - val_accuracy: 0.2287 - val_loss: 1.9079\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2113 - loss: 1.9140 - val_accuracy: 0.2287 - val_loss: 1.8977\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2525 - loss: 1.7650 - val_accuracy: 0.2422 - val_loss: 1.8867\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3596 - loss: 1.6573 - val_accuracy: 0.2466 - val_loss: 1.8837\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4182 - loss: 1.5146 - val_accuracy: 0.2511 - val_loss: 1.8820\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5034 - loss: 1.2858 - val_accuracy: 0.2601 - val_loss: 1.9516\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5884 - loss: 1.0587 - val_accuracy: 0.2466 - val_loss: 2.0999\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6707 - loss: 0.9024 - val_accuracy: 0.2332 - val_loss: 2.1773\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7166 - loss: 0.8227 - val_accuracy: 0.2018 - val_loss: 2.3295\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7234 - loss: 0.7146 - val_accuracy: 0.2063 - val_loss: 2.4338\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7988 - loss: 0.5964 - val_accuracy: 0.1614 - val_loss: 2.7912\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8265 - loss: 0.5156 - val_accuracy: 0.1928 - val_loss: 2.7696\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8276 - loss: 0.4725 - val_accuracy: 0.1883 - val_loss: 2.8286\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8215 - loss: 0.4837 - val_accuracy: 0.2018 - val_loss: 2.8757\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8523 - loss: 0.4197 - val_accuracy: 0.1883 - val_loss: 3.3946\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8806 - loss: 0.3512 - val_accuracy: 0.1973 - val_loss: 3.2915\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8950 - loss: 0.3186 - val_accuracy: 0.2018 - val_loss: 3.4227\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9093 - loss: 0.3106 - val_accuracy: 0.1839 - val_loss: 3.5794\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9070 - loss: 0.3070 - val_accuracy: 0.1928 - val_loss: 3.9141\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1803 - loss: 4.0245 \n",
      "Test Loss: 3.9301161766052246\n",
      "Test Accuracy: 0.1928251087665558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "\n",
    "# Convert text data to numerical vectors\n",
    "count_vectorizer = CountVectorizer(max_features=max_features)\n",
    "x_data = count_vectorizer.fit_transform(stripped_data['Text']).toarray()\n",
    "\n",
    "# Ordinal encoding for emotion\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "y_data = ordinal_encoder.fit_transform(stripped_data[['Emotion']])\n",
    "y_data = y_data.reshape(-1)  # Reshape to a 1D array\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=y_data, random_state=42)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Dense(embedding_dim, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Reshape((embedding_dim, 1)))  # Reshape to match Conv1D input shape\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(np.unique(y_data)), activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with VAE encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m vae \u001b[38;5;241m=\u001b[39m Model(inputs, x_decoded_mean)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# VAE loss\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m xent_loss \u001b[38;5;241m=\u001b[39m input_dim \u001b[38;5;241m*\u001b[39m \u001b[43mmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_decoded_mean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m K\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m z_log_var \u001b[38;5;241m-\u001b[39m K\u001b[38;5;241m.\u001b[39msquare(z_mean) \u001b[38;5;241m-\u001b[39m K\u001b[38;5;241m.\u001b[39mexp(z_log_var), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     55\u001b[0m vae_loss \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mmean(xent_loss \u001b[38;5;241m+\u001b[39m kl_loss)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses\\losses.py:1151\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[0;32m   1119\u001b[0m     [\n\u001b[0;32m   1120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.metrics.mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m )\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(y_true, y_pred):\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;124;03m\"\"\"Computes the mean squared error between labels and predictions.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[0;32m   1132\u001b[0m \u001b[38;5;124;03m    Formula:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;124;03m        Mean squared error values with shape = `[batch_size, d0, .. dN-1]`.\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1151\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_true, dtype\u001b[38;5;241m=\u001b[39my_pred\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   1153\u001b[0m     y_true, y_pred \u001b[38;5;241m=\u001b[39m squeeze_or_expand_to_same_rank(y_true, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\ops\\core.py:493\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(x, dtype, sparse)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.ops.convert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor\u001b[39m(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;124;03m\"\"\"Convert a NumPy array to a tensor.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;124;03m    >>> y = keras.ops.convert_to_tensor(x)\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:115\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(x, dtype, sparse)\u001b[0m\n\u001b[0;32m    113\u001b[0m         x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py:92\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with BagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(891, 4528)\n",
      "(891, 8)\n",
      "Shape of test data:\n",
      "(223, 4528)\n",
      "(223, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">452,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_26         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m452,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_38 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_26         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,444</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m462,444\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,444</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m462,444\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1885 - loss: 2.0457 - val_accuracy: 0.2287 - val_loss: 1.9250\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2200 - loss: 1.9256 - val_accuracy: 0.2287 - val_loss: 1.9088\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2501 - loss: 1.8600 - val_accuracy: 0.2287 - val_loss: 1.9038\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2306 - loss: 1.7750 - val_accuracy: 0.2108 - val_loss: 1.8996\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2579 - loss: 1.6610 - val_accuracy: 0.2242 - val_loss: 1.8975\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3238 - loss: 1.4764 - val_accuracy: 0.2242 - val_loss: 1.9108\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4875 - loss: 1.3091 - val_accuracy: 0.2242 - val_loss: 1.9892\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6044 - loss: 1.1177 - val_accuracy: 0.1883 - val_loss: 2.1395\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6719 - loss: 0.9416 - val_accuracy: 0.2287 - val_loss: 2.2336\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6983 - loss: 0.8271 - val_accuracy: 0.1794 - val_loss: 2.4420\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7553 - loss: 0.7512 - val_accuracy: 0.1794 - val_loss: 2.7360\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.6358 - val_accuracy: 0.1614 - val_loss: 2.8148\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.5959 - val_accuracy: 0.1480 - val_loss: 2.9757\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.5121 - val_accuracy: 0.1570 - val_loss: 3.0950\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8506 - loss: 0.4548 - val_accuracy: 0.1345 - val_loss: 3.4070\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8632 - loss: 0.4192 - val_accuracy: 0.1480 - val_loss: 3.5632\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.3786 - val_accuracy: 0.1390 - val_loss: 4.0053\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.3721 - val_accuracy: 0.1570 - val_loss: 4.0827\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8959 - loss: 0.3140 - val_accuracy: 0.1525 - val_loss: 4.1761\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9128 - loss: 0.2855 - val_accuracy: 0.1435 - val_loss: 4.5112\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1468 - loss: 4.4822 \n",
      "Test Loss: 4.407915115356445\n",
      "Test Accuracy: 0.1434977650642395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bag-of-Words Vectorization\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=max_features)\n",
    "x_data = count_vectorizer.fit_transform(stripped_data['Text']).toarray()\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "\n",
    "print('Shape of training data:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data:')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Dense(embedding_dim, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Reshape((embedding_dim, 1)))  # Reshape to match Conv1D input shape\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(891, 4528)\n",
      "(891, 8)\n",
      "Shape of test data:\n",
      "(223, 4528)\n",
      "(223, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">452,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_25         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m452,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_37 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_25         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,444</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m462,444\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">462,444</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m462,444\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1501 - loss: 2.0580 - val_accuracy: 0.2018 - val_loss: 1.9547\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2266 - loss: 1.9650 - val_accuracy: 0.2287 - val_loss: 1.9098\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2500 - loss: 1.8966 - val_accuracy: 0.2287 - val_loss: 1.9067\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1797 - loss: 1.8572 - val_accuracy: 0.2287 - val_loss: 1.8954\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2202 - loss: 1.7114 - val_accuracy: 0.2287 - val_loss: 1.9081\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2708 - loss: 1.5327 - val_accuracy: 0.1928 - val_loss: 1.9478\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3168 - loss: 1.4539 - val_accuracy: 0.2063 - val_loss: 1.9977\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3695 - loss: 1.3892 - val_accuracy: 0.2063 - val_loss: 2.0603\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4856 - loss: 1.2372 - val_accuracy: 0.1839 - val_loss: 2.1771\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5697 - loss: 1.0790 - val_accuracy: 0.1480 - val_loss: 2.4069\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7001 - loss: 0.8819 - val_accuracy: 0.1570 - val_loss: 2.5921\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7602 - loss: 0.7146 - val_accuracy: 0.1480 - val_loss: 2.9175\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7717 - loss: 0.6120 - val_accuracy: 0.1614 - val_loss: 3.2577\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8271 - loss: 0.4760 - val_accuracy: 0.1749 - val_loss: 3.4486\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8363 - loss: 0.4795 - val_accuracy: 0.1794 - val_loss: 3.7203\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8460 - loss: 0.4272 - val_accuracy: 0.1659 - val_loss: 3.9447\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8773 - loss: 0.3593 - val_accuracy: 0.1659 - val_loss: 4.1764\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8786 - loss: 0.3365 - val_accuracy: 0.1570 - val_loss: 4.4526\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.2886 - val_accuracy: 0.1390 - val_loss: 4.9086\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8894 - loss: 0.2707 - val_accuracy: 0.1390 - val_loss: 4.9789\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1455 - loss: 4.7813 \n",
      "Test Loss: 4.9567413330078125\n",
      "Test Accuracy: 0.13901345431804657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=max_features)\n",
    "x_data = tfidf.fit_transform(stripped_data['Text']).toarray()\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "\n",
    "print('Shape of training data:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data:')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Dense(embedding_dim, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Reshape((embedding_dim, 1)))  # Reshape to match Conv1D input shape\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data:\n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_23         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_29 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_35 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_23         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.2182 - loss: 2.0100 - val_accuracy: 0.2332 - val_loss: 1.9093\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2855 - loss: 1.8577 - val_accuracy: 0.2018 - val_loss: 1.9055\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5333 - loss: 1.6271 - val_accuracy: 0.2556 - val_loss: 1.8884\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6905 - loss: 1.1494 - val_accuracy: 0.2422 - val_loss: 1.8789\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8362 - loss: 0.5687 - val_accuracy: 0.2332 - val_loss: 1.9573\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9634 - loss: 0.2866 - val_accuracy: 0.2422 - val_loss: 2.0414\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9896 - loss: 0.1099 - val_accuracy: 0.2691 - val_loss: 2.0933\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9943 - loss: 0.0557 - val_accuracy: 0.2825 - val_loss: 2.1864\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9857 - loss: 0.0499 - val_accuracy: 0.2646 - val_loss: 2.1565\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9856 - loss: 0.0538 - val_accuracy: 0.2601 - val_loss: 2.1559\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9947 - loss: 0.0244 - val_accuracy: 0.2735 - val_loss: 2.1782\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9962 - loss: 0.0190 - val_accuracy: 0.2556 - val_loss: 2.2163\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9986 - loss: 0.0114 - val_accuracy: 0.2601 - val_loss: 2.2459\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9973 - loss: 0.0112 - val_accuracy: 0.2466 - val_loss: 2.4094\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9982 - loss: 0.0116 - val_accuracy: 0.2691 - val_loss: 2.2577\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9954 - loss: 0.0219 - val_accuracy: 0.2646 - val_loss: 2.4106\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9936 - loss: 0.0131 - val_accuracy: 0.2735 - val_loss: 2.4215\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9978 - loss: 0.0112 - val_accuracy: 0.2377 - val_loss: 2.3646\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9890 - loss: 0.0258 - val_accuracy: 0.2735 - val_loss: 2.5684\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9972 - loss: 0.0113 - val_accuracy: 0.2466 - val_loss: 2.4574\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2320 - loss: 2.5071 \n",
      "Test Loss: 2.5305473804473877\n",
      "Test Accuracy: 0.2466367781162262\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and Padding using Tokenizer with n-grams\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "n_gram_range = 2  # Unigram and bigram\n",
    "\n",
    "# Function to add n-grams\n",
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "def add_ngram(sequences, token_index, ngram_range=2):\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for ngram_value in range(2, ngram_range + 1):\n",
    "            for ngram in create_ngram_set(input_list, ngram_value):\n",
    "                if ngram in token_index:\n",
    "                    new_list.append(token_index[ngram])\n",
    "                else:\n",
    "                    # Add a new token to the index\n",
    "                    token_index[ngram] = len(token_index) + 1\n",
    "                    new_list.append(token_index[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "    return new_sequences\n",
    "\n",
    "# Tokenizer initialization and fitting\n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(stripped_data['Text'])\n",
    "\n",
    "# Convert texts to sequences\n",
    "sequences = tokenizer.texts_to_sequences(stripped_data['Text'])\n",
    "\n",
    "# Add n-gram features\n",
    "token_index = tokenizer.word_index.copy()  # Copy the word index\n",
    "sequences_ngram = add_ngram(sequences, token_index, n_gram_range)\n",
    "\n",
    "# Pad sequences\n",
    "x_data = pad_sequences(sequences_ngram, maxlen=max_len)\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "\n",
    "print('Shape of training data:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data:')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(token_index) + 1, output_dim=embedding_dim))  # Adjust input_dim\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Mark II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_16         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">808</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_19 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m1,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m20,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m40,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_16         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m808\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,101,208</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,101,208\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,101,208</span> (4.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,101,208\u001b[0m (4.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1669 - loss: 2.0340 - val_accuracy: 0.2287 - val_loss: 1.9101\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.2304 - loss: 1.9629 - val_accuracy: 0.1570 - val_loss: 1.9051\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2347 - loss: 1.9061 - val_accuracy: 0.2332 - val_loss: 1.8958\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2995 - loss: 1.7757 - val_accuracy: 0.2287 - val_loss: 1.9401\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4514 - loss: 1.4344 - val_accuracy: 0.2332 - val_loss: 2.2247\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5480 - loss: 1.1780 - val_accuracy: 0.1928 - val_loss: 2.7669\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6196 - loss: 0.9783 - val_accuracy: 0.1749 - val_loss: 3.3798\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6796 - loss: 0.8216 - val_accuracy: 0.1704 - val_loss: 3.8527\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7193 - loss: 0.7348 - val_accuracy: 0.1749 - val_loss: 4.3492\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7845 - loss: 0.5945 - val_accuracy: 0.1570 - val_loss: 4.9084\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8055 - loss: 0.4856 - val_accuracy: 0.1839 - val_loss: 5.2256\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8181 - loss: 0.4761 - val_accuracy: 0.1704 - val_loss: 5.4903\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8406 - loss: 0.4345 - val_accuracy: 0.1435 - val_loss: 5.7081\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8696 - loss: 0.3471 - val_accuracy: 0.1659 - val_loss: 6.1494\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8709 - loss: 0.3313 - val_accuracy: 0.2108 - val_loss: 6.3081\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8974 - loss: 0.2487 - val_accuracy: 0.2108 - val_loss: 6.8424\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9053 - loss: 0.2654 - val_accuracy: 0.1839 - val_loss: 7.1072\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8986 - loss: 0.2520 - val_accuracy: 0.1839 - val_loss: 7.2217\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9198 - loss: 0.2242 - val_accuracy: 0.2063 - val_loss: 7.3870\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8994 - loss: 0.2578 - val_accuracy: 0.2152 - val_loss: 7.1512\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2052 - loss: 7.6637 \n",
      "Test Loss: 7.306800842285156\n",
      "Test Accuracy: 0.21524663269519806\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_len,), dtype='int32'))\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(100, 2, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Conv1D(100, 4, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax')) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with SMOTE (for undistributed data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_17         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_20 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_17         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.1349 - loss: 2.0789 - val_accuracy: 0.0942 - val_loss: 2.0851\n",
      "Epoch 2/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3062 - loss: 1.9835 - val_accuracy: 0.1345 - val_loss: 2.0463\n",
      "Epoch 3/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6105 - loss: 1.5777 - val_accuracy: 0.2242 - val_loss: 1.9634\n",
      "Epoch 4/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8194 - loss: 0.8121 - val_accuracy: 0.2287 - val_loss: 2.0867\n",
      "Epoch 5/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9487 - loss: 0.3090 - val_accuracy: 0.2511 - val_loss: 2.3690\n",
      "Epoch 6/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9733 - loss: 0.1369 - val_accuracy: 0.2646 - val_loss: 2.5188\n",
      "Epoch 7/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9898 - loss: 0.0701 - val_accuracy: 0.2825 - val_loss: 2.6400\n",
      "Epoch 8/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9936 - loss: 0.0383 - val_accuracy: 0.2646 - val_loss: 2.7855\n",
      "Epoch 9/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0284 - val_accuracy: 0.2466 - val_loss: 2.9215\n",
      "Epoch 10/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9965 - loss: 0.0219 - val_accuracy: 0.2377 - val_loss: 3.0376\n",
      "Epoch 11/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0140 - val_accuracy: 0.2377 - val_loss: 3.1038\n",
      "Epoch 12/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9985 - loss: 0.0161 - val_accuracy: 0.2511 - val_loss: 3.1701\n",
      "Epoch 13/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9939 - loss: 0.0169 - val_accuracy: 0.2466 - val_loss: 3.2370\n",
      "Epoch 14/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9973 - loss: 0.0112 - val_accuracy: 0.2556 - val_loss: 3.3592\n",
      "Epoch 15/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0086 - val_accuracy: 0.2556 - val_loss: 3.4353\n",
      "Epoch 16/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.2780 - val_loss: 3.4825\n",
      "Epoch 17/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9987 - loss: 0.0117 - val_accuracy: 0.2601 - val_loss: 3.5261\n",
      "Epoch 18/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0059 - val_accuracy: 0.2466 - val_loss: 3.6004\n",
      "Epoch 19/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9973 - loss: 0.0069 - val_accuracy: 0.2466 - val_loss: 3.6081\n",
      "Epoch 20/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0067 - val_accuracy: 0.2691 - val_loss: 3.6303\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2498 - loss: 3.7071 \n",
      "Test Loss: 3.775036573410034\n",
      "Test Accuracy: 0.2690582871437073\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20#30\n",
    "epochs = 20\n",
    "model.fit(X_train_resampled, y_train_resampled, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Class Weights (for undistributed data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_18         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_21 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_18         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1739 - loss: 2.0832 - val_accuracy: 0.1031 - val_loss: 2.0702\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3333 - loss: 1.9949 - val_accuracy: 0.1435 - val_loss: 2.0757\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5517 - loss: 1.8354 - val_accuracy: 0.1076 - val_loss: 2.0628\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7168 - loss: 1.5758 - val_accuracy: 0.1928 - val_loss: 1.9732\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8834 - loss: 0.9808 - val_accuracy: 0.1973 - val_loss: 1.9095\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9454 - loss: 0.4049 - val_accuracy: 0.2377 - val_loss: 1.9755\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9752 - loss: 0.1785 - val_accuracy: 0.2466 - val_loss: 2.0488\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0895 - val_accuracy: 0.2377 - val_loss: 2.1484\n",
      "Epoch 9/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9920 - loss: 0.0551 - val_accuracy: 0.2422 - val_loss: 2.1944\n",
      "Epoch 10/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9892 - loss: 0.0376 - val_accuracy: 0.2332 - val_loss: 2.2718\n",
      "Epoch 11/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9947 - loss: 0.0289 - val_accuracy: 0.2691 - val_loss: 2.3280\n",
      "Epoch 12/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0371 - val_accuracy: 0.2287 - val_loss: 2.4128\n",
      "Epoch 13/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0254 - val_accuracy: 0.2511 - val_loss: 2.4551\n",
      "Epoch 14/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9963 - loss: 0.0181 - val_accuracy: 0.2332 - val_loss: 2.4952\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9930 - loss: 0.0211 - val_accuracy: 0.2511 - val_loss: 2.5087\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9863 - loss: 0.0264 - val_accuracy: 0.2646 - val_loss: 2.5779\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0105 - val_accuracy: 0.2601 - val_loss: 2.5837\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9988 - loss: 0.0100 - val_accuracy: 0.2511 - val_loss: 2.6006\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9958 - loss: 0.0132 - val_accuracy: 0.2152 - val_loss: 2.6821\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9968 - loss: 0.0163 - val_accuracy: 0.2556 - val_loss: 2.7152\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2494 - loss: 2.8303 \n",
      "Test Loss: 2.8647234439849854\n",
      "Test Accuracy: 0.2556053698062897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(stripped_data['Emotion']), y=stripped_data['Emotion'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_19         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_24 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_19         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.1815 - loss: 2.4653 - val_accuracy: 0.0404 - val_loss: 2.4290\n",
      "Epoch 2/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2077 - loss: 2.0112 - val_accuracy: 0.1121 - val_loss: 2.1888\n",
      "Epoch 3/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3522 - loss: 1.5446 - val_accuracy: 0.1121 - val_loss: 2.1660\n",
      "Epoch 4/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4381 - loss: 1.3949 - val_accuracy: 0.1525 - val_loss: 2.0429\n",
      "Epoch 5/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5834 - loss: 1.2993 - val_accuracy: 0.2152 - val_loss: 2.0372\n",
      "Epoch 6/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6861 - loss: 1.0340 - val_accuracy: 0.2556 - val_loss: 1.9600\n",
      "Epoch 7/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8480 - loss: 0.7176 - val_accuracy: 0.2646 - val_loss: 1.9901\n",
      "Epoch 8/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9202 - loss: 0.3352 - val_accuracy: 0.2601 - val_loss: 2.0928\n",
      "Epoch 9/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9585 - loss: 0.1785 - val_accuracy: 0.2422 - val_loss: 2.3541\n",
      "Epoch 10/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9840 - loss: 0.1029 - val_accuracy: 0.2556 - val_loss: 2.4555\n",
      "Epoch 11/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9834 - loss: 0.0813 - val_accuracy: 0.2825 - val_loss: 2.5346\n",
      "Epoch 12/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9929 - loss: 0.0481 - val_accuracy: 0.2556 - val_loss: 2.5468\n",
      "Epoch 13/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.0416 - val_accuracy: 0.2601 - val_loss: 2.7544\n",
      "Epoch 14/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9969 - loss: 0.0218 - val_accuracy: 0.2556 - val_loss: 2.7812\n",
      "Epoch 15/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0186 - val_accuracy: 0.2691 - val_loss: 2.8411\n",
      "Epoch 16/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0246 - val_accuracy: 0.2646 - val_loss: 2.8717\n",
      "Epoch 17/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.0177 - val_accuracy: 0.2511 - val_loss: 2.9784\n",
      "Epoch 18/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9954 - loss: 0.0195 - val_accuracy: 0.2691 - val_loss: 2.9551\n",
      "Epoch 19/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0148 - val_accuracy: 0.2691 - val_loss: 3.0495\n",
      "Epoch 20/20\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9927 - loss: 0.0210 - val_accuracy: 0.2960 - val_loss: 3.0645\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2584 - loss: 3.4425 \n",
      "Test Loss: 3.2628962993621826\n",
      "Test Accuracy: 0.2959641218185425\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "adasyn = ADASYN(sampling_strategy='minority')\n",
    "X_res, y_res = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_res, y_res, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_20         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_25 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_20         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1377 - loss: 2.8829 - val_accuracy: 0.0404 - val_loss: 2.2148\n",
      "Epoch 2/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1404 - loss: 2.6899 - val_accuracy: 0.0404 - val_loss: 2.5009\n",
      "Epoch 3/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1527 - loss: 2.3526 - val_accuracy: 0.0493 - val_loss: 2.6865\n",
      "Epoch 4/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1649 - loss: 2.2119 - val_accuracy: 0.0628 - val_loss: 2.6645\n",
      "Epoch 5/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2935 - loss: 1.9680 - val_accuracy: 0.0538 - val_loss: 2.7248\n",
      "Epoch 6/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3891 - loss: 1.6739 - val_accuracy: 0.0583 - val_loss: 2.7089\n",
      "Epoch 7/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5004 - loss: 1.5364 - val_accuracy: 0.0583 - val_loss: 2.6585\n",
      "Epoch 8/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4885 - loss: 1.2973 - val_accuracy: 0.0628 - val_loss: 2.6418\n",
      "Epoch 9/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6233 - loss: 1.0919 - val_accuracy: 0.0628 - val_loss: 2.6027\n",
      "Epoch 10/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6473 - loss: 0.8645 - val_accuracy: 0.0762 - val_loss: 2.5576\n",
      "Epoch 11/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7808 - loss: 0.5987 - val_accuracy: 0.0942 - val_loss: 2.4934\n",
      "Epoch 12/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9286 - loss: 0.4884 - val_accuracy: 0.0987 - val_loss: 2.5729\n",
      "Epoch 13/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9618 - loss: 0.3012 - val_accuracy: 0.0942 - val_loss: 2.5969\n",
      "Epoch 14/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9673 - loss: 0.2257 - val_accuracy: 0.0987 - val_loss: 2.8169\n",
      "Epoch 15/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9883 - loss: 0.1546 - val_accuracy: 0.1211 - val_loss: 2.7628\n",
      "Epoch 16/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9941 - loss: 0.1036 - val_accuracy: 0.1076 - val_loss: 2.9090\n",
      "Epoch 17/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9988 - loss: 0.0761 - val_accuracy: 0.1076 - val_loss: 3.0547\n",
      "Epoch 18/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9959 - loss: 0.0604 - val_accuracy: 0.1166 - val_loss: 3.0209\n",
      "Epoch 19/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.0449 - val_accuracy: 0.1076 - val_loss: 3.1965\n",
      "Epoch 20/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9830 - loss: 0.0488 - val_accuracy: 0.1076 - val_loss: 3.1698\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0973 - loss: 3.3747 \n",
      "Test Loss: 3.209712505340576\n",
      "Test Accuracy: 0.10762331634759903\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "nearmiss = NearMiss(version=1)\n",
    "X_res, y_res = nearmiss.fit_resample(X_train, y_train)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_res, y_res, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Borderline_SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_21         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_26 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_21         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1315 - loss: 2.7196 - val_accuracy: 0.0493 - val_loss: 2.5378\n",
      "Epoch 2/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1819 - loss: 2.3430 - val_accuracy: 0.0852 - val_loss: 2.4847\n",
      "Epoch 3/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3269 - loss: 1.8853 - val_accuracy: 0.1031 - val_loss: 2.4954\n",
      "Epoch 4/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4362 - loss: 1.5413 - val_accuracy: 0.1121 - val_loss: 2.2885\n",
      "Epoch 5/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6287 - loss: 0.9865 - val_accuracy: 0.1614 - val_loss: 2.2652\n",
      "Epoch 6/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8162 - loss: 0.4973 - val_accuracy: 0.1883 - val_loss: 2.3710\n",
      "Epoch 7/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9168 - loss: 0.2577 - val_accuracy: 0.1794 - val_loss: 2.6485\n",
      "Epoch 8/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9675 - loss: 0.1297 - val_accuracy: 0.2197 - val_loss: 2.8810\n",
      "Epoch 9/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9863 - loss: 0.0763 - val_accuracy: 0.2108 - val_loss: 3.2188\n",
      "Epoch 10/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9894 - loss: 0.0499 - val_accuracy: 0.2108 - val_loss: 3.4294\n",
      "Epoch 11/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0401 - val_accuracy: 0.2197 - val_loss: 3.6115\n",
      "Epoch 12/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.0238 - val_accuracy: 0.1973 - val_loss: 3.8153\n",
      "Epoch 13/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0210 - val_accuracy: 0.2063 - val_loss: 4.0006\n",
      "Epoch 14/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9938 - loss: 0.0227 - val_accuracy: 0.2063 - val_loss: 4.0906\n",
      "Epoch 15/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0175 - val_accuracy: 0.2197 - val_loss: 4.2912\n",
      "Epoch 16/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0108 - val_accuracy: 0.1973 - val_loss: 4.3812\n",
      "Epoch 17/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9978 - loss: 0.0145 - val_accuracy: 0.2152 - val_loss: 4.6342\n",
      "Epoch 18/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.0099 - val_accuracy: 0.2197 - val_loss: 4.8636\n",
      "Epoch 19/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9969 - loss: 0.0118 - val_accuracy: 0.1928 - val_loss: 5.0469\n",
      "Epoch 20/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9983 - loss: 0.0142 - val_accuracy: 0.1883 - val_loss: 4.9680\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1740 - loss: 5.2019 \n",
      "Test Loss: 4.991868019104004\n",
      "Test Accuracy: 0.18834081292152405\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "borderline_smote = BorderlineSMOTE()\n",
    "X_res, y_res = borderline_smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_res, y_res, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with SMOTE + Tomek Links (SMOTETomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_22         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_27 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_34 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_22         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1413 - loss: 2.8264 - val_accuracy: 0.0404 - val_loss: 2.7048\n",
      "Epoch 2/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1651 - loss: 2.5030 - val_accuracy: 0.0673 - val_loss: 2.4157\n",
      "Epoch 3/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2964 - loss: 1.9595 - val_accuracy: 0.0942 - val_loss: 2.3688\n",
      "Epoch 4/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4902 - loss: 1.3773 - val_accuracy: 0.1076 - val_loss: 2.2584\n",
      "Epoch 5/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6765 - loss: 0.7539 - val_accuracy: 0.2108 - val_loss: 2.2075\n",
      "Epoch 6/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8223 - loss: 0.4419 - val_accuracy: 0.2108 - val_loss: 2.2713\n",
      "Epoch 7/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9410 - loss: 0.2110 - val_accuracy: 0.2197 - val_loss: 2.4744\n",
      "Epoch 8/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9719 - loss: 0.1174 - val_accuracy: 0.2332 - val_loss: 2.7648\n",
      "Epoch 9/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9819 - loss: 0.0714 - val_accuracy: 0.2197 - val_loss: 3.0174\n",
      "Epoch 10/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9938 - loss: 0.0466 - val_accuracy: 0.2466 - val_loss: 3.1905\n",
      "Epoch 11/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9928 - loss: 0.0438 - val_accuracy: 0.2422 - val_loss: 3.2913\n",
      "Epoch 12/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9973 - loss: 0.0205 - val_accuracy: 0.2287 - val_loss: 3.4729\n",
      "Epoch 13/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9960 - loss: 0.0215 - val_accuracy: 0.2287 - val_loss: 3.5774\n",
      "Epoch 14/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0141 - val_accuracy: 0.2152 - val_loss: 3.7056\n",
      "Epoch 15/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9979 - loss: 0.0153 - val_accuracy: 0.2108 - val_loss: 3.8343\n",
      "Epoch 16/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0114 - val_accuracy: 0.2152 - val_loss: 3.9369\n",
      "Epoch 17/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 0.2152 - val_loss: 3.8825\n",
      "Epoch 18/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0121 - val_accuracy: 0.2242 - val_loss: 4.0345\n",
      "Epoch 19/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0099 - val_accuracy: 0.2018 - val_loss: 4.2513\n",
      "Epoch 20/20\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9935 - loss: 0.0170 - val_accuracy: 0.2108 - val_loss: 4.1654\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2121 - loss: 4.7172 \n",
      "Test Loss: 4.426326751708984\n",
      "Test Accuracy: 0.21076233685016632\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "smote_tomek = SMOTETomek()\n",
    "X_res, y_res = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# CNN Model Architecture\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim))  # Specify input_dim instead of input_length\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "model.fit(X_res, y_res, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Embedding: {'weights': [array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.0377471 ,  0.04051033,  0.01418809, ..., -0.05840995,\n         0.00959121, -0.00311465],\n       [-0.04275942,  0.04129154,  0.01375338, ..., -0.04937395,\n        -0.00240904, -0.00474263],\n       ...,\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ]])]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Input(shape\u001b[38;5;241m=\u001b[39m(max_len,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 43\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43membedding_matrix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Pre-trained Word2Vec embeddings\u001b[39;00m\n\u001b[1;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:81\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, embeddings_constraint, mask_zero, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     72\u001b[0m     input_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     80\u001b[0m ):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m=\u001b[39m input_dim\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/layer.py:265\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_policy \u001b[38;5;241m=\u001b[39m dtype_policies\u001b[38;5;241m.\u001b[39mget(dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Embedding: {'weights': [array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.0377471 ,  0.04051033,  0.01418809, ..., -0.05840995,\n         0.00959121, -0.00311465],\n       [-0.04275942,  0.04129154,  0.01375338, ..., -0.04937395,\n        -0.00240904, -0.00474263],\n       ...,\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ]])]}"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(stripped_data['Emotion']), y=stripped_data['Emotion'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Train Word2Vec model\n",
    "texts = stripped_data['Text'].apply(lambda x: x.split())\n",
    "word2vec_model = Word2Vec(sentences=texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "word_index = tokenizer.word_index\n",
    "for word, i in word_index.items():\n",
    "    if i < max_features:\n",
    "        try:\n",
    "            embedding_vector = word2vec_model.wv[word]\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "# Build CNN Model with Word2Vec embeddings\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_len,), dtype='int32'))\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False))  # Pre-trained Word2Vec embeddings\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN GloVe embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(891, 100)\n",
      "(891, 8)\n",
      "Shape of test data: \n",
      "(223, 100)\n",
      "(223, 8)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Embedding: {'weights': [array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n         0.82779998,  0.27061999],\n       [-0.10767   ,  0.11053   ,  0.59811997, ..., -0.83155   ,\n         0.45293   ,  0.082577  ],\n       ...,\n       [ 0.21675999,  0.23662999,  0.72715998, ..., -0.24111   ,\n         0.51990998,  0.75832999],\n       [ 0.05649   ,  1.19550002, -0.15339001, ...,  0.16537   ,\n         0.41398001, -0.28968999],\n       [-1.10350001,  0.67953998, -0.11548   , ..., -1.1947    ,\n         0.26718   , -0.50117999]])]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Input(shape\u001b[38;5;241m=\u001b[39m(max_len,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 55\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43membedding_matrix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Pre-trained GloVe embeddings\u001b[39;00m\n\u001b[1;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:81\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, embeddings_constraint, mask_zero, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     72\u001b[0m     input_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     80\u001b[0m ):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m=\u001b[39m input_dim\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/layer.py:265\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_policy \u001b[38;5;241m=\u001b[39m dtype_policies\u001b[38;5;241m.\u001b[39mget(dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Embedding: {'weights': [array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n         0.        ,  0.        ],\n       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n         0.82779998,  0.27061999],\n       [-0.10767   ,  0.11053   ,  0.59811997, ..., -0.83155   ,\n         0.45293   ,  0.082577  ],\n       ...,\n       [ 0.21675999,  0.23662999,  0.72715998, ..., -0.24111   ,\n         0.51990998,  0.75832999],\n       [ 0.05649   ,  1.19550002, -0.15339001, ...,  0.16537   ,\n         0.41398001, -0.28968999],\n       [-1.10350001,  0.67953998, -0.11548   , ..., -1.1947    ,\n         0.26718   , -0.50117999]])]}"
     ]
    }
   ],
   "source": [
    "# Load GloVe embeddings\n",
    "embedding_dim = 100\n",
    "# gloVe_loc = \"../data/glove.840B.300d.txt\"  # Path to GloVe file\n",
    "gloVe_loc = \"../data/glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "\n",
    "# Determine embedding dimension automatically\n",
    "with open(gloVe_loc, 'r', encoding='utf-8') as f:\n",
    "    first_line = f.readline()\n",
    "    embedding_dim = len(first_line.split()) - 1  # The number of dimensions is one less than the number of columns\n",
    "\n",
    "# Reload the GloVe file to build the embeddings_index\n",
    "with open(gloVe_loc, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        except ValueError:\n",
    "            print(f\"Skipping line: {line}\")\n",
    "            \n",
    "# Tokenization and Padding using one_hot\n",
    "max_features = 10000  # Max number of words in tokenizer\n",
    "max_len = 100  # Max length of each sequence (pad/truncate to this length)\n",
    "encoded_docs = [one_hot(d, max_features) for d in stripped_data['Text']]\n",
    "x_data = pad_sequences(encoded_docs, maxlen=max_len)\n",
    "y_data = pd.get_dummies(stripped_data['Emotion']).values  # Convert categorical labels to one-hot encoded vectors\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, stratify=stripped_data['Emotion'], random_state=42)\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(stripped_data['Emotion']), y=stripped_data['Emotion'])\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "word_index = {word: i for i, word in enumerate(embeddings_index.keys(), 1)}  # Build word index\n",
    "for word, i in word_index.items():\n",
    "    if i < max_features:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Build CNN Model with GloVe embeddings\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(max_len,), dtype='int32'))\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False))  # Pre-trained GloVe embeddings\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_data.shape[1], activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
