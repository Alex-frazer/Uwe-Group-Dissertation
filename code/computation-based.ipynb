{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational-based \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2142 entries, 0 to 2141\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Online Post ID          2142 non-null   int64  \n",
      " 1   Twitter ID              1673 non-null   float64\n",
      " 2   Related Online Post ID  333 non-null    float64\n",
      " 3   Source ID               2142 non-null   object \n",
      " 4   Online Post Text        469 non-null    object \n",
      " 5   Subjectivity            2142 non-null   int64  \n",
      " 6   Sentiment Polarity      2142 non-null   object \n",
      " 7   Emotion                 2142 non-null   object \n",
      " 8   Sarcasm                 2142 non-null   int64  \n",
      " 9   Irony                   2142 non-null   int64  \n",
      " 10  Negation                2142 non-null   int64  \n",
      " 11  Off-topic               2142 non-null   int64  \n",
      " 12  Language                2142 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 217.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2316 entries, 0 to 2315\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Online Post ID          2316 non-null   int64  \n",
      " 1   Twitter ID              1677 non-null   float64\n",
      " 2   Related Online Post ID  448 non-null    float64\n",
      " 3   Source ID               2316 non-null   object \n",
      " 4   Online Post Text        639 non-null    object \n",
      " 5   Subjectivity            2316 non-null   int64  \n",
      " 6   Sentiment Polarity      2316 non-null   object \n",
      " 7   Emotion                 2316 non-null   object \n",
      " 8   Sarcasm                 2316 non-null   int64  \n",
      " 9   Irony                   2316 non-null   int64  \n",
      " 10  Negation                2316 non-null   int64  \n",
      " 11  Off-topic               2316 non-null   int64  \n",
      " 12  Language                2316 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 235.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1929 entries, 0 to 1928\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Online Post ID          1929 non-null   int64  \n",
      " 1   Twitter ID              1314 non-null   float64\n",
      " 2   Related Online Post ID  396 non-null    float64\n",
      " 3   Source ID               1929 non-null   object \n",
      " 4   Online Post Text        615 non-null    object \n",
      " 5   Subjectivity            1929 non-null   int64  \n",
      " 6   Sentiment Polarity      1929 non-null   object \n",
      " 7   Emotion                 1929 non-null   object \n",
      " 8   Sarcasm                 1929 non-null   int64  \n",
      " 9   Irony                   1929 non-null   int64  \n",
      " 10  Negation                1929 non-null   int64  \n",
      " 11  Off-topic               1929 non-null   int64  \n",
      " 12  Language                1929 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 196.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6387 entries, 0 to 6386\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Online Post ID          6387 non-null   int64  \n",
      " 1   Twitter ID              4664 non-null   float64\n",
      " 2   Related Online Post ID  1177 non-null   float64\n",
      " 3   Source ID               6387 non-null   object \n",
      " 4   Online Post Text        1723 non-null   object \n",
      " 5   Subjectivity            6387 non-null   int64  \n",
      " 6   Sentiment Polarity      6387 non-null   object \n",
      " 7   Emotion                 6387 non-null   object \n",
      " 8   Sarcasm                 6387 non-null   int64  \n",
      " 9   Irony                   6387 non-null   int64  \n",
      " 10  Negation                6387 non-null   int64  \n",
      " 11  Off-topic               6387 non-null   int64  \n",
      " 12  Language                6387 non-null   int64  \n",
      "dtypes: float64(2), int64(7), object(4)\n",
      "memory usage: 648.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Irony</th>\n",
       "      <th>Negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>20200659</td>\n",
       "      <td>Wow growing together, so I will get a 17 black...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>20200660</td>\n",
       "      <td>Equal pay for equal work to be introduced in t...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5070</th>\n",
       "      <td>20200661</td>\n",
       "      <td>No cash when worth more then 10000?. Use offsh...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5071</th>\n",
       "      <td>20200662</td>\n",
       "      <td>Budget 2020 reactions: Some say it’s good, oth...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>20200663</td>\n",
       "      <td>Budget 2020 reactions: Some say it’s good, oth...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text  \\\n",
       "5068  20200659  Wow growing together, so I will get a 17 black...   \n",
       "5069  20200660  Equal pay for equal work to be introduced in t...   \n",
       "5070  20200661  No cash when worth more then 10000?. Use offsh...   \n",
       "5071  20200662  Budget 2020 reactions: Some say it’s good, oth...   \n",
       "5072  20200663  Budget 2020 reactions: Some say it’s good, oth...   \n",
       "\n",
       "      Subjectivity Sentiment Polarity       Emotion  Sarcasm  Irony  Negation  \n",
       "5068             1           positive       disgust        0      1         0  \n",
       "5069             1           positive  anticipation        0      0         1  \n",
       "5070             1           negative  anticipation        0      1         0  \n",
       "5071             1           negative         anger        0      0         0  \n",
       "5072             1            neutral       sadness        0      0         0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "malta_loc_18 = '../data/Malta-Budget-2018-dataset-v1.csv'\n",
    "malta_loc_19 = '../data/Malta-Budget-2019-dataset-v1.csv'\n",
    "malta_loc_20 = '../data/Malta-Budget-2020-dataset-v1.csv'\n",
    "\n",
    "malta_data_18 = pd.read_csv(malta_loc_18)\n",
    "malta_data_19 = pd.read_csv(malta_loc_19)\n",
    "malta_data_20 = pd.read_csv(malta_loc_20)\n",
    "\n",
    "print(malta_data_18.info())\n",
    "print(malta_data_19.info())\n",
    "print(malta_data_20.info())\n",
    "\n",
    "malta_data_19 = malta_data_19.rename(columns={'Off-topic ':'Off-topic'})\n",
    "combined_data = pd.concat([malta_data_18, malta_data_19, malta_data_20], ignore_index=True)\n",
    "combined_data.info()\n",
    "\n",
    "clean_data = combined_data.dropna(subset=['Online Post Text'])\n",
    "clean_data = clean_data.drop(['Twitter ID', 'Related Online Post ID', 'Source ID','Off-topic'], axis=1)\n",
    "clean_data = clean_data[clean_data['Language'] == 0] # get all data that is in english \n",
    "clean_data = clean_data.drop(['Language'], axis=1)\n",
    "clean_data = clean_data.rename(columns={'Online Post ID':'ID','Online Post Text':'Text'})\n",
    "\n",
    "\n",
    "# clean_data = clean_data.drop(['ID','Subjectivity', 'Sentiment Polarity', 'Sarcasm', 'Irony', 'Negation'], axis=1)\n",
    "\n",
    "clean_data.head()\n",
    "clean_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (151 > 100). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Sentiment Polarity</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Irony</th>\n",
       "      <th>Negation</th>\n",
       "      <th>Raw_Text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>padded</th>\n",
       "      <th>masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180001</td>\n",
       "      <td>great budget even cigarette touched great work...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Great BUDGET . Even cigarettes were not touche...</td>\n",
       "      <td>[great, budget, even, ci, ##gare, ##tte, touch...</td>\n",
       "      <td>[101, 11838, 21455, 12818, 11200, 46511, 11993...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180002</td>\n",
       "      <td>exactly scanned budget throughout earth make i...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I haven't exactly scanned the budget throughou...</td>\n",
       "      <td>[exactly, sc, ##anne, ##d, budget, throughout,...</td>\n",
       "      <td>[101, 56938, 16427, 31570, 10163, 21455, 15410...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180003</td>\n",
       "      <td>already smoking cessation program people want ...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There’s already smoking cessation programs for...</td>\n",
       "      <td>[already, smoking, ces, ##sation, program, peo...</td>\n",
       "      <td>[101, 18874, 67503, 12139, 22337, 11660, 11227...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180004</td>\n",
       "      <td>alcohol fuel private vehicle raising tax cigar...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>So should alcohol and fuel for private vehicle...</td>\n",
       "      <td>[alcohol, fuel, private, vehicle, raising, tax...</td>\n",
       "      <td>[101, 31329, 26150, 13742, 23247, 47651, 22389...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180005</td>\n",
       "      <td>practical say third world country supposed eur...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Practical? You should say that in a third worl...</td>\n",
       "      <td>[practical, say, third, world, country, suppos...</td>\n",
       "      <td>[101, 37872, 16497, 12047, 10228, 11913, 54838...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               Text  Subjectivity  \\\n",
       "0  20180001  great budget even cigarette touched great work...             1   \n",
       "1  20180002  exactly scanned budget throughout earth make i...             1   \n",
       "2  20180003  already smoking cessation program people want ...             1   \n",
       "3  20180004  alcohol fuel private vehicle raising tax cigar...             1   \n",
       "4  20180005  practical say third world country supposed eur...             1   \n",
       "\n",
       "  Sentiment Polarity       Emotion  Sarcasm  Irony  Negation  \\\n",
       "0           positive         trust        0      0         1   \n",
       "1           negative       disgust        0      0         1   \n",
       "2            neutral  anticipation        0      0         0   \n",
       "3           negative       sadness        0      0         0   \n",
       "4           negative         anger        0      0         1   \n",
       "\n",
       "                                            Raw_Text  \\\n",
       "0  Great BUDGET . Even cigarettes were not touche...   \n",
       "1  I haven't exactly scanned the budget throughou...   \n",
       "2  There’s already smoking cessation programs for...   \n",
       "3  So should alcohol and fuel for private vehicle...   \n",
       "4  Practical? You should say that in a third worl...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [great, budget, even, ci, ##gare, ##tte, touch...   \n",
       "1  [exactly, sc, ##anne, ##d, budget, throughout,...   \n",
       "2  [already, smoking, ces, ##sation, program, peo...   \n",
       "3  [alcohol, fuel, private, vehicle, raising, tax...   \n",
       "4  [practical, say, third, world, country, suppos...   \n",
       "\n",
       "                                              padded  \\\n",
       "0  [101, 11838, 21455, 12818, 11200, 46511, 11993...   \n",
       "1  [101, 56938, 16427, 31570, 10163, 21455, 15410...   \n",
       "2  [101, 18874, 67503, 12139, 22337, 11660, 11227...   \n",
       "3  [101, 31329, 26150, 13742, 23247, 47651, 22389...   \n",
       "4  [101, 37872, 16497, 12047, 10228, 11913, 54838...   \n",
       "\n",
       "                                               masks  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle text processing and tokenisation:\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "\n",
    "processed_data = clean_data.copy(deep=True)\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    pattern = re.compile(r'[^a-zA-Z\\s]')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "# Remove URLs and HTML tags\n",
    "processed_data['Raw_Text'] = processed_data['Text']\n",
    "\n",
    "processed_data['Text'] = processed_data['Text'].str.replace(r'http\\S+|www\\S+|https\\S+', '', regex=True)\n",
    "processed_data['Text'] = processed_data['Text'].str.replace(r'<.*?>', '', regex=True)\n",
    "\n",
    "# Expand contractions\n",
    "processed_data['Text'] = processed_data['Text'].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "# Convert to lowercase\n",
    "processed_data['Text'] = processed_data['Text'].str.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "processed_data['Text'] = processed_data['Text'].str.replace(f\"[{string.punctuation}]\", \" \", regex=True)\n",
    "\n",
    "# Remove numbers\n",
    "processed_data['Text'] = processed_data['Text'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "# Remove special characters\n",
    "processed_data['Text'] = processed_data['Text'].apply(remove_special_characters)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed_data['Text'] = processed_data['Text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "\n",
    "# Remove extra whitespace\n",
    "processed_data['Text'] = processed_data['Text'].str.strip()\n",
    "processed_data['Text'] = processed_data['Text'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "processed_data['Text'] = processed_data['Text'].apply(lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split()))\n",
    "\n",
    "# Tokenize\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') #30522 \n",
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "tokenizer.model_max_length = 100\n",
    "tokenizer_features = 30522\n",
    "processed_data['tokens'] = processed_data['Text'].apply(lambda x: tokenizer.tokenize(x)) \n",
    "\n",
    "max_words = processed_data['Text'].apply(lambda x: len(x.split())).max()\n",
    "\n",
    "max_tokens = processed_data['tokens'].apply(lambda x: len(x)).max()\n",
    "\n",
    "def encode_texts(texts, tokenizer, max_len): \n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    \n",
    "    return input_ids, attention_masks\n",
    "\n",
    "processed_data['padded'], processed_data['masks'] = encode_texts(processed_data['Text'].tolist(), tokenizer, 100)\n",
    "\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID                                               Text  \\\n",
      "0     20180001  great budget even cigarette touched great work...   \n",
      "1     20180002  exactly scanned budget throughout earth make i...   \n",
      "2     20180003  already smoking cessation program people want ...   \n",
      "3     20180004  alcohol fuel private vehicle raising tax cigar...   \n",
      "4     20180005  practical say third world country supposed eur...   \n",
      "...        ...                                                ...   \n",
      "5068  20200659              wow growing together get black budget   \n",
      "5069  20200660  equal pay equal work introduced private sector...   \n",
      "5070  20200661                    cash worth use offshore account   \n",
      "5071  20200662  budget reaction say good others say bad earnes...   \n",
      "5072  20200663  budget reaction say good others say bad happen...   \n",
      "\n",
      "      Subjectivity Sentiment Polarity       Emotion  Sarcasm  Irony  Negation  \\\n",
      "0                1           positive         trust        0      0         1   \n",
      "1                1           negative       disgust        0      0         1   \n",
      "2                1            neutral  anticipation        0      0         0   \n",
      "3                1           negative       sadness        0      0         0   \n",
      "4                1           negative         anger        0      0         1   \n",
      "...            ...                ...           ...      ...    ...       ...   \n",
      "5068             1           positive       disgust        0      1         0   \n",
      "5069             1           positive  anticipation        0      0         1   \n",
      "5070             1           negative  anticipation        0      1         0   \n",
      "5071             1           negative         anger        0      0         0   \n",
      "5072             1            neutral       sadness        0      0         0   \n",
      "\n",
      "                                               Raw_Text  \\\n",
      "0     Great BUDGET . Even cigarettes were not touche...   \n",
      "1     I haven't exactly scanned the budget throughou...   \n",
      "2     There’s already smoking cessation programs for...   \n",
      "3     So should alcohol and fuel for private vehicle...   \n",
      "4     Practical? You should say that in a third worl...   \n",
      "...                                                 ...   \n",
      "5068  Wow growing together, so I will get a 17 black...   \n",
      "5069  Equal pay for equal work to be introduced in t...   \n",
      "5070  No cash when worth more then 10000?. Use offsh...   \n",
      "5071  Budget 2020 reactions: Some say it’s good, oth...   \n",
      "5072  Budget 2020 reactions: Some say it’s good, oth...   \n",
      "\n",
      "                                                 tokens  \\\n",
      "0     [great, budget, even, ci, ##gare, ##tte, touch...   \n",
      "1     [exactly, sc, ##anne, ##d, budget, throughout,...   \n",
      "2     [already, smoking, ces, ##sation, program, peo...   \n",
      "3     [alcohol, fuel, private, vehicle, raising, tax...   \n",
      "4     [practical, say, third, world, country, suppos...   \n",
      "...                                                 ...   \n",
      "5068       [wow, growing, together, get, black, budget]   \n",
      "5069  [equal, pay, equal, work, introduced, private,...   \n",
      "5070              [cash, worth, use, offshore, account]   \n",
      "5071  [budget, reaction, say, good, others, say, bad...   \n",
      "5072  [budget, reaction, say, good, others, say, bad...   \n",
      "\n",
      "                                                 padded  \\\n",
      "0     [101, 11838, 21455, 12818, 11200, 46511, 11993...   \n",
      "1     [101, 56938, 16427, 31570, 10163, 21455, 15410...   \n",
      "2     [101, 18874, 67503, 12139, 22337, 11660, 11227...   \n",
      "3     [101, 31329, 26150, 13742, 23247, 47651, 22389...   \n",
      "4     [101, 37872, 16497, 12047, 10228, 11913, 54838...   \n",
      "...                                                 ...   \n",
      "5068  [101, 94608, 23148, 13627, 13168, 11418, 21455...   \n",
      "5069  [101, 29531, 11498, 29531, 11497, 17200, 13742...   \n",
      "5070  [101, 26509, 25840, 11868, 66176, 21157, 102, ...   \n",
      "5071  [101, 21455, 25274, 16497, 12050, 14399, 16497...   \n",
      "5072  [101, 21455, 25274, 16497, 12050, 14399, 16497...   \n",
      "\n",
      "                                                  masks  exclamation_count  \\\n",
      "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                  0   \n",
      "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                  2   \n",
      "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                  0   \n",
      "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                  0   \n",
      "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...                  0   \n",
      "...                                                 ...                ...   \n",
      "5068  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...                  0   \n",
      "5069  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                  0   \n",
      "5070  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...                  0   \n",
      "5071  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                  1   \n",
      "5072  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...                  0   \n",
      "\n",
      "      question_count  ellipsis_count  comma_count  period_count  \n",
      "0                  0               0            0             5  \n",
      "1                  1               0            1             0  \n",
      "2                  0               0            0             0  \n",
      "3                  1               1            2             2  \n",
      "4                  1               0            1             0  \n",
      "...              ...             ...          ...           ...  \n",
      "5068               1               0            1             0  \n",
      "5069               1               0            5             1  \n",
      "5070               1               0            0             1  \n",
      "5071               0               1            1             1  \n",
      "5072               1               0            1             0  \n",
      "\n",
      "[1114 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count Punctuation\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def count_punctuation(text):\n",
    "    exclamation_count = len(re.findall(r'!', text))\n",
    "    question_count = len(re.findall(r'\\?', text))\n",
    "    ellipsis_count = len(re.findall(r'\\.\\.\\.', text))\n",
    "    comma_count = len(re.findall(r',', text))\n",
    "    period_count = len(re.findall(r'\\. ', text))\n",
    "    return pd.Series({\n",
    "        'exclamation_count': exclamation_count,\n",
    "        'question_count': question_count,\n",
    "        'ellipsis_count': ellipsis_count,\n",
    "        'comma_count': comma_count,\n",
    "        'period_count': period_count\n",
    "    })\n",
    "    \n",
    "processed_data = processed_data.join(processed_data['Raw_Text'].apply(count_punctuation))\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "#getting Polarity. \n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoModelForSequenceClassification\n",
    "\n",
    "# Load sentiment analysis pipeline\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "sentiment_analyzer = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    result = sentiment_analyzer(text)\n",
    "    return result\n",
    "\n",
    "processed_data['sentiment_score'] = tqdm(processed_data['tokens'].apply(get_sentiment))\n",
    "\n",
    "print(processed_data.head)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
